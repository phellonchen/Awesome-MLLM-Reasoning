# Awesome-MLLM-Reasoning
Reasoning in MLLMs: Papers and Resources; Latest Advances on Reasoning of Multimodal Large Language Models (Multimodal R1) ) üçì

<font size=5><center><b> Table of Contents </b> </center></font>
- [Awesome Technique](#awesome-technique)
- [Awesome Datasets](#awesome-datasets)
---

## Awesome Technique
|  Title  |   Code  |   About / Paper   |
|:--------|:--------:|:--------:|
|![Star](https://img.shields.io/github/stars/EvolvingLMMs-Lab/open-r1-multimodal.svg?style=social&label=Star) <br> **EvolvingLMMs-Lab/open-r1-multimodal** <br> | [Github](https://github.com/EvolvingLMMs-Lab/open-r1-multimodal) | A fork to add multimodal model training to open-r1 |
|![Star](https://img.shields.io/github/stars/Deep-Agent/R1-V.svg?style=social&label=Star) <br> **Deep-Agent/R1-V** <br> | [Github](https://github.com/Deep-Agent/R1-V) | Witness the aha moment of VLM with less than $3. |
|![Star](https://img.shields.io/github/stars/TideDra/lmm-r1.svg?style=social&label=Star) <br> **TideDra/lmm-r1** <br> | [Github](https://github.com/TideDra/lmm-r1) | Extend OpenRLHF to support LMM RL training for reproduction of DeepSeek-R1 on multimodal tasks. |
|![Star](https://img.shields.io/github/stars/FanqingM/R1-Multimodal-Journey.svg?style=social&label=Star) <br> **FanqingM/R1-Multimodal-Journey** <br> | [Github](https://github.com/FanqingM/R1-Multimodal-Journey) | A jounery to real multimodel R1 ! We are doing on large-scale experiment |
|![Star](https://img.shields.io/github/stars/yuyq96/R1-Vision.svg?style=social&label=Star) <br> **yuyq96/R1-Vision** <br> | [Github](https://github.com/yuyq96/R1-Vision) | R1-Vision: Let's first take a look at the image |
|![Star](https://img.shields.io/github/stars/phellonchen/Visual-R1.svg?style=social&label=Star) <br> **phellonchen/Visual-R1** <br> | [Github](https://github.com/phellonchen/Visual-R1) | Visual R1: Transfer Reasoning Ability from R1 to Visual R1 |
|![Star](https://img.shields.io/github/stars/om-ai-lab/VLM-R1.svg?style=social&label=Star) <br> **om-ai-lab/VLM-R1** <br> | [Github](https://github.com/om-ai-lab/VLM-R1) | VLM-R1: A stable and generalizable R1-style Large Vision-Language Model |
|![Star](https://img.shields.io/github/stars/ModalMinds/MM-EUREKA.svg?style=social&label=Star) <br> **ModalMinds/MM-EUREKA** <br> | [Github](https://github.com/ModalMinds/MM-EUREKA) | MM-EUREKA: Exploring Visual Aha Moment with Rule-based Large-scale Reinforcement Learning |
|![Star](https://img.shields.io/github/stars/jingyi0000/R1-VL.svg?style=social&label=Star) <br> **jingyi0000/R1-VL** <br> | [Github](https://github.com/jingyi0000/R1-VL) | [R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization](https://arxiv.org/html/2503.12937v1) |


## Awesome Datasets
| Name | Paper | Link | Modalities |
|:-----|:-----:|:----:|:----------:|
| **multimodal-open-r1-8k-verified** | - | [Link](https://huggingface.co/datasets/lmms-lab/multimodal-open-r1-8k-verified) | Vision + Text |
| **R1-Vision** | R1-Vision: Let's first take a look at the image | [Link](https://huggingface.co/collections/yuyq96/r1-vision-67a6fb7898423dca453efa83) | Vision + Text |
| **CLEVR-70k-Counting** | - | [Link](https://huggingface.co/datasets/leonardPKU/clevr_cogen_a_train) | Vision + Text |
| **CLEVR-70k-Complex** | - | [Link](https://huggingface.co/datasets/MMInstruction/Clevr_CoGenT_TrainA_70K_Complex) | Vision + Text |
| **GEOQA-8k** | - | [Link](https://huggingface.co/datasets/leonardPKU/GEOQA_R1V_Train_8K) | Vision + Text |
| **Clevr_CoGenT_TrainA_R1** | - | [Link](https://huggingface.co/datasets/MMInstruction/Clevr_CoGenT_TrainA_R1) | Vision + Text |
| **MM-Eureka-Dataset** | - | [Link](https://huggingface.co/datasets/FanqingM/MM-Eureka-Dataset) | Vision + Text |
| **Open-Thoughts-114k** | - | [Link](https://huggingface.co/datasets/leonardPKU/GEOQA_R1V_Train_8K) | Text |
| **OpenThoughts-Unverified-173k** | - | [Link](https://huggingface.co/datasets/open-thoughts/OpenThoughts-Unverified-173k) | Text |
| **Chinese-DeepSeek-R1-Distill-data-110k** | - | [Link](https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k) | Text |

## Citation
If you find this project useful in your research, please consider cite:
```
@misc{chen25mllmr1,
  author       = {Feilong Chen},
  title        = {Awesome-MLLM-Reasoning},
  howpublished = {\url{https://github.com/phellonchen/Awesome-MLLM-Reasoning}},
  note         = {Accessed: 2025-02-15},
  year         = {2025}
}
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=phellonchen/Awesome-MLLM-Reasoning&type=Timeline)](https://star-history.com/#phellonchen/Awesome-MLLM-Reasoning&Timeline)

